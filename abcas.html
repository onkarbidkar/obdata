<p>
ML 1 :- LR
import matplotlib.pyplot as plt <br>
import pandas as pd <br>
from google.colab import files <br>
uploaded = files.upload<br>
file uploaded<br>
#Read Dataset<br>
dataset=pd.read_csv("hours.csv")<br>
#index read <br>
x=dataset.iloc[:,:-1].values  #slice all column<br>
y=dataset.iloc[:,1].values  #last Column<br>
#import packages of LR<br>
from sklearn.linear_model import LinearRegression<br>
regressor=LinearRegression() #create object of LR<br>

# Fit Function<br>
regressor.fit(x,y)<br>

#score Function<br>
Accuracy=regressor.score(x,y)*100<br>
print('Accuracy')<br>
print(Accuracy)<br>

#Predict Function<br>
y_pred=regressor.predict([[10]])<br>
print(y_pred)
<br>
#input from user
hours=int(input("Enter the no of hours"))<br>

# Coefficient  # intercept<br>
eq=regressor.coef_*hours+regressor.intercept_<br>
print("Risk Score",eq[0])<br>

plt.plot(x,y,'o')<br>
plt.plot(x,regressor.predict(x));<br>
plt.show()

</p>

<p>
ML 2 :- DC<br>
import matplotlib.pyplot as plt<br>
import pandas as pd<br>
from google.colab import files<br>
uploaded = files.upload<br>

file uploaded<br>
# Read dataset<br>
dataset=pd.read_csv("tree1.csv")<br>

x=dataset.iloc[:,:-1]<br>
y=dataset.iloc[:,5]
<br>
#Label encoder<br>
from sklearn.preprocessing import LabelEncoder<br>
le=LabelEncoder()<br>
x=x.apply(le.fit_transform)<br>
print(x)<br>

# 1 1 0 0
#import Decesion Tree Classifier

from sklearn.tree import DecisionTreeClassifier<br>
# Create decision tree classifer object<br>
regressor=DecisionTreeClassifier()<br>
# Train model<br>
regressor.fit(x.iloc[:,1:5],y)<br>

x_in=np.array([1,1,0,0])<br>
y_pred=regressor.predict([x_in])<br>

print("Predicted class for input [Age < 21, Income =Low,Gender = Female, Marital Status = Married]\n", x_in," is",y_pred[0])<br>

from six import StringIO<br>
#from IPython.display import Image<br>
from sklearn.tree import export_graphviz<br>
import pydotplus
<br>
dot_data=StringIO()<br>
export_graphviz(regressor,out_file=dot_data,filled=True,rounded=True,special_characters=True)<br>

#Draw Graph<br>
graph=pydotplus.graph_from_dot_data(dot_data.getvalue())<br>

# Show graph & Create png File<br>
graph.write_png("tree.png")<br><br>
#Image(graph.create_png())<br>

</p>
<p>
ML3 :- KNN
import matplotlib.pyplot as plt<br>
import pandas as pd<br>
from google.colab import files<br>
uploaded = files.upload<br>
file uploaded<br>

dataset=pd.read_csv("kdata.csv")<br>
X=dataset.iloc[:,:-1].values<br>
y=dataset.iloc[:,2].values<br>

#import KNeighborshood Classifier and create object of it
from sklearn.neighbors import KNeighborsClassifier<br>

#Creating model<br>
classifier=KNeighborsClassifier(n_neighbors=3)<br>
# Training model<br>
classifier.fit(X,y)<br>

#predict the class for the point(6,6)<br>
X_test=np.array([6,6])<br>
# Predictions for test data<br>
y_pred=classifier.predict([X_test])<br>
print("class of the point (6,6) : ",y_pred)<br>

# KNeighborsClassifier looks for the 5 nearest neighbors<br>
#If set to uniform, all points in each neighbourhood have <br>
#equal influence in predicting class i.e. predicted class is the class with highest number of points in the neighbourhood.<br>
classifier=KNeighborsClassifier(n_neighbors=3,weights='distance')<br>
classifier.fit(X,y)<br>


#predict the class for the point(6,2)<br>
X_test=np.array([6,2])<br>
y_pred=classifier.predict([X_test])<br>
print("Distance-Weighted k-NN : class of the point (6,2). ",y_pred)<br>
</p>

<p>
ML4- KM

import numpy as np<br>
import matplotlib.pyplot as plt<br>
import pandas as pd<br>
<br>
#create dataset using DataFrame<br>
df=pd.DataFrame({'X':[0.1,0.15,0.08,0.16,0.2,0.25,0.24,0.3],<br>
                 'y':[0.6,0.71,0.9,0.85,0.3,0.5,0.1,0.2]})<br>
f1 = df['X'].values<br>
f2 = df['y'].values<br><br>
X = np.array(list(zip(f1, f2)))<br>
print(X)<br>

#centroid points<br>
C_x=np.array([0.1,0.3])<br>
C_y=np.array([0.6,0.2])<br>
centroids=C_x,C_y<br>

#plot the given points<br>
colmap = {1: 'r', 2: 'b'}<br>
plt.scatter(f1, f2, color='k')<br>
plt.show()<br>

#for i in centroids():<br>
plt.scatter(C_x[0],C_y[0], color=colmap[1])<br>
plt.scatter(C_x[1],C_y[1], color=colmap[2])<br>
plt.show()<br>
C = np.array(list((C_x, C_y)), dtype=np.float32)<br>
print (C)<br>

#plot given elements with centroid elements<br>
plt.scatter(f1, f2, c='#050505')<br>
plt.scatter(C_x[0], C_y[0], marker='*', s=200, c='r')<br>
plt.scatter(C_x[1], C_y[1], marker='*', s=200, c='b')<br>
plt.show()<br>

#import KMeans class and create object of it<br>
from sklearn.cluster import KMeans<br>
model=KMeans(n_clusters=2,random_state=0)<br>
model.fit(X)<br>
labels=model.labels_<br>
print(labels)<br>

#using labels find population around centroid<br>
count=0<br>
for i in range(len(labels)):<br>
    if (labels[i]==1):<br>
        count=count+1<br>
print('No of population around cluster 2:',count-1)<br>
	
#Find new centroids<br>
new_centroids = model.cluster_centers_<br>
print('Previous value of m1 and m2 is:')<br>
print('M1==',centroids[0])<br><br>
print('M1==',centroids[1])<br>
print('updated value of m1 and m2 is:')<br>
print('M1==',new_centroids[0])<br>
print('M1==',new_centroids[1])<br>

</p>
